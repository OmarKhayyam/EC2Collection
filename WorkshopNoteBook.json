{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501384750900_1971038180","id":"20170730-031910_107912823","dateCreated":"2017-07-30T03:19:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:272","text":"%pyspark\nfrom pyspark.sql import SparkSession,DataFrame,Column,SQLContext\nfrom pyspark.sql import functions as Fun\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\nimport pyspark\nimport os,sys","dateUpdated":"2017-07-30T04:38:57+0000","dateFinished":"2017-07-30T04:38:57+0000","dateStarted":"2017-07-30T04:38:57+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n## Set up your bucket to read from","user":"anonymous","dateUpdated":"2017-07-30T04:38:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501386774301_1968609261","id":"20170730-035254_45177238","dateCreated":"2017-07-30T03:52:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2238","dateFinished":"2017-07-30T04:38:58+0000","dateStarted":"2017-07-30T04:38:58+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Set up your bucket to read from</h2>\n"}]}},{"text":"%pyspark\nROsrcBkt = \"s3://rnsbucketinput/\" # For all the general input data for this workshop\nMydestBkt = \"s3://rnsbucketinput/\" # This is where you have stored your personal ratings","user":"anonymous","dateUpdated":"2017-07-30T04:39:01+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501384822208_2000587224","id":"20170730-032022_415428052","dateCreated":"2017-07-30T03:20:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:342","dateFinished":"2017-07-30T04:39:01+0000","dateStarted":"2017-07-30T04:39:01+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n## Read the user's ratings for the various movies and build a Spark DataFrame from the file","user":"anonymous","dateUpdated":"2017-07-30T04:39:02+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501386823953_1620857552","id":"20170730-035343_1847607834","dateCreated":"2017-07-30T03:53:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2318","dateFinished":"2017-07-30T04:39:02+0000","dateStarted":"2017-07-30T04:39:02+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Read the user's ratings for the various movies and build a Spark DataFrame from the file</h2>\n"}]}},{"text":"%pyspark\nratingsDF = spark.read.option(\"header\",\"true\").csv(ROsrcBkt+\"ratings.csv\")","user":"anonymous","dateUpdated":"2017-07-30T04:39:06+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501384929789_-257934792","id":"20170730-032209_191507062","dateCreated":"2017-07-30T03:22:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:414","dateFinished":"2017-07-30T04:39:07+0000","dateStarted":"2017-07-30T04:39:06+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n## Split the dataset\n\nIt is standard practice to split the dataset into a training, validation and test sets. The training set, obviously, is used for training, and the validation set is used to check the efficacy of the model we have built using the training set. Finally, the test set is used to check the quality of the model and is used only once when we have found a model that is acceptable based on the training and validation sets.","user":"anonymous","dateUpdated":"2017-07-30T04:39:09+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501386912703_-1861365181","id":"20170730-035512_239500133","dateCreated":"2017-07-30T03:55:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2398","dateFinished":"2017-07-30T04:39:09+0000","dateStarted":"2017-07-30T04:39:09+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Split the dataset</h2>\n<p>It is standard practice to split the dataset into a training, validation and test sets. The training set, obviously, is used for training, and the validation set is used to check the efficacy of the model we have built using the training set. Finally, the test set is used to check the quality of the model and is used only once when we have found a model that is acceptable based on the training and validation sets.</p>\n"}]}},{"text":"%pyspark\nseed = 42\n(trngDF,valDF,testDF) = ratingsDF.randomSplit([0.6,0.2,0.2],seed)\ntrngDF.persist()\nvalDF.persist()\ntestDF.persist()","user":"anonymous","dateUpdated":"2017-07-30T04:39:13+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501384972850_670677198","id":"20170730-032252_356680483","dateCreated":"2017-07-30T03:22:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:497","dateFinished":"2017-07-30T04:39:13+0000","dateStarted":"2017-07-30T04:39:13+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[userId: string, movieId: string, rating: string, timestamp: string]\n"}]}},{"text":"%md\n## We create our own ratings DataFrame. We then include it in our training dataset to train our model on it.","user":"anonymous","dateUpdated":"2017-07-30T04:39:16+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501388063456_1309818453","id":"20170730-041423_1192096452","dateCreated":"2017-07-30T04:14:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2558","dateFinished":"2017-07-30T04:39:16+0000","dateStarted":"2017-07-30T04:39:16+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>We create our own ratings DataFrame. We then include it in our training dataset to train our model on it.</h2>\n"}]}},{"text":"%pyspark\nmyRatingsDF = spark.read.option(\"header\",\"false\").csv(MydestBkt+\"personalRatings.txt\")\nnTrngDF = trngDF.drop('timestamp').union(myRatingsDF)","user":"anonymous","dateUpdated":"2017-07-30T04:39:20+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501385084001_-235220927","id":"20170730-032444_319217432","dateCreated":"2017-07-30T03:24:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:568","dateFinished":"2017-07-30T04:39:20+0000","dateStarted":"2017-07-30T04:39:20+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\nnnTrngDF = nTrngDF.select(nTrngDF.userId.cast(\"int\"),nTrngDF.movieId.cast(\"int\"),nTrngDF.rating.cast(\"float\"))\nnnTrngDF.persist()\ntrngDF.unpersist()\nnValDF = valDF.select(valDF.userId.cast(\"int\"),valDF.movieId.cast(\"int\"),valDF.rating.cast(\"float\"))\nnValDF.persist()\nnTestDF = testDF.select(testDF.userId.cast(\"int\"),testDF.movieId.cast(\"int\"),testDF.rating.cast(\"float\"))\nnTestDF.persist()\nvalDF.unpersist()\ntestDF.unpersist()\nnnTrngDF.printSchema()\nnValDF.printSchema()\nnTestDF.printSchema()","user":"anonymous","dateUpdated":"2017-07-30T04:39:23+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501385120243_-2128154867","id":"20170730-032520_1769237067","dateCreated":"2017-07-30T03:25:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:655","dateFinished":"2017-07-30T04:39:23+0000","dateStarted":"2017-07-30T04:39:23+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- rating: float (nullable = true)\n\nroot\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- rating: float (nullable = true)\n\nroot\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- rating: float (nullable = true)\n\n"}]}},{"text":"%pyspark\nnnTrngDF.registerTempTable('trainingset')","user":"anonymous","dateUpdated":"2017-07-30T04:39:26+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501388983577_-330108363","id":"20170730-042943_1971837936","dateCreated":"2017-07-30T04:29:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3127","dateFinished":"2017-07-30T04:39:26+0000","dateStarted":"2017-07-30T04:39:26+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%sql\nselect movieId,count(rating) as ratingCount from trainingset group by movieId limit 5","user":"anonymous","dateUpdated":"2017-07-30T05:44:30+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501389186708_-1739753356","id":"20170730-043306_1891342099","dateCreated":"2017-07-30T04:33:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3183","dateFinished":"2017-07-30T05:44:30+0000","dateStarted":"2017-07-30T05:44:30+0000","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"movieId\tratingCount\n1238\t14\n2366\t12\n2866\t7\n471\t28\n1580\t132\n"}]}},{"text":"%sql\nselect rating,count(movieId) as movieCount from trainingset group by rating","user":"anonymous","dateUpdated":"2017-07-30T05:52:35+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501393852575_-555367439","id":"20170730-055052_728398921","dateCreated":"2017-07-30T05:50:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5251","dateFinished":"2017-07-30T05:52:21+0000","dateStarted":"2017-07-30T05:52:20+0000","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"rating\tmovieCount\n5.0\t9148\n2.5\t2669\n2.0\t4316\n3.0\t11979\n1.5\t1040\n0.5\t680\n3.5\t6339\n1.0\t1981\n4.5\t4706\n4.0\t17290\n0.0\t2\n"}]}},{"text":"%md\n## Here we set the Ranks of the factor matrices, the maximum number of iterations that we allow before ALS will reach an acceptable value, we also decide on a [regularization parameter](https://en.wikipedia.org/wiki/Regularization_(mathematics)) and the learning rate, you can find more about [learning rate here](https://en.wikipedia.org/wiki/Gradient_descent). ","user":"anonymous","dateUpdated":"2017-07-30T04:23:55+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501388171890_1955548056","id":"20170730-041611_550821143","dateCreated":"2017-07-30T04:16:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2684","dateFinished":"2017-07-30T04:23:55+0000","dateStarted":"2017-07-30T04:23:55+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Here we set the Ranks of the factor matrices, the maximum number of iterations that we allow before ALS will reach an acceptable value, we also decide on a <a href=\"https://en.wikipedia.org/wiki/Regularization_(mathematics)\">regularization parameter</a> and the learning rate, you can find more about <a href=\"https://en.wikipedia.org/wiki/Gradient_descent\">learning rate here</a>.</h2>\n"}]}},{"text":"%pyspark\nirank = [21,22,23]\niterations = 20\nireg = 0.2\nilearn = 1.0\nmodel = None\noldrmse = None","user":"anonymous","dateUpdated":"2017-07-30T03:47:31+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501385569812_231168071","id":"20170730-033249_1204275026","dateCreated":"2017-07-30T03:32:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:906","dateFinished":"2017-07-30T03:47:31+0000","dateStarted":"2017-07-30T03:47:31+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n## Here we try various values for the hyperparameters, in the case below we have only changed Rank, but you could try changing other parameters too and see what effect they have on the models you generate.","user":"anonymous","dateUpdated":"2017-07-30T04:25:44+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501388658107_-1746063104","id":"20170730-042418_2071871240","dateCreated":"2017-07-30T04:24:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2804","dateFinished":"2017-07-30T04:25:44+0000","dateStarted":"2017-07-30T04:25:44+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Here we try various values for the hyperparameters, in the case below we have only changed Rank, but you could try changing other parameters too and see what effect they have on the models you generate.</h2>\n"}]}},{"text":"%pyspark\nfor r in irank:\n        newmodel = None\n        alsresult = ALS(rank=r,maxIter=iterations,regParam=ireg,alpha=ilearn,userCol=\"userId\",itemCol=\"movieId\",ratingCol=\"rating\")\n        newmodel = alsresult.fit(nnTrngDF)\n        predictions = newmodel.transform(nValDF)\n        evaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\n        rmse = evaluator.evaluate(predictions.filter(predictions.prediction != float('nan')))\n        print(\"Found model with Root Mean Squared Error of {0:3.4f}.\".format(rmse))\n        if not model:\n            model = newmodel\n            oldrmse = rmse\n        else:\n            if oldrmse > rmse:\n                model = newmodel\n                oldrmse = rmse\nnnTrngDF.unpersist()\nnValDF.unpersist()\nprint(\"Identified best model whose Root Mean Squared Error on Validation data is {0:3.4f}.\".format(oldrmse))","user":"anonymous","dateUpdated":"2017-07-30T03:47:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501385598034_-2002437211","id":"20170730-033318_1579191451","dateCreated":"2017-07-30T03:33:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:993","dateFinished":"2017-07-30T03:48:17+0000","dateStarted":"2017-07-30T03:47:36+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found model with Root Mean Squared Error of 0.9305.\nFound model with Root Mean Squared Error of 0.9306.\nFound model with Root Mean Squared Error of 0.9310.\nIdentified best model whose Root Mean Squared Error on Validation data is 0.9305.\n"}]}},{"text":"%md\n## __NOTE__ : We have to skip the 'nan' values, this is due to a peculiarity in the k-folds cross validation used in Spark ML. You can read all about the details [here](https://issues.apache.org/jira/browse/SPARK-14489).","user":"anonymous","dateUpdated":"2017-07-30T04:29:14+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501388864434_-1279238450","id":"20170730-042744_863334511","dateCreated":"2017-07-30T04:27:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3044","dateFinished":"2017-07-30T04:29:14+0000","dateStarted":"2017-07-30T04:29:14+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2><strong>NOTE</strong> : We have to skip the 'nan' values, this is due to a peculiarity in the k-folds cross validation used in Spark ML. You can read all about the details <a href=\"https://issues.apache.org/jira/browse/SPARK-14489\">here</a>.</h2>\n"}]}},{"text":"%pyspark\npredictions = model.transform(nTestDF)\nevaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")\noldrmse = evaluator.evaluate(predictions.filter(predictions.prediction != float('nan')))\nprint(\"The best model we have chosen gives us a RMSE of {0:3.4f} on our test dataset.\".format(oldrmse))","user":"anonymous","dateUpdated":"2017-07-30T03:48:20+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501385661093_-1086842098","id":"20170730-033421_815456329","dateCreated":"2017-07-30T03:34:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1064","dateFinished":"2017-07-30T03:49:00+0000","dateStarted":"2017-07-30T03:48:20+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"The best model we have chosen gives us a RMSE of 0.9156 on our test dataset.\n"}]}},{"text":"%md\n## We find the RMSE for the average ratings model, to compare it with the quality of the best model we chose above.","user":"anonymous","dateUpdated":"2017-07-30T04:26:52+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501388758240_1823037904","id":"20170730-042558_788412169","dateCreated":"2017-07-30T04:25:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2884","dateFinished":"2017-07-30T04:26:52+0000","dateStarted":"2017-07-30T04:26:52+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>We find the RMSE for the average ratings model, to compare it with the quality of the best model we chose above.</h2>\n"}]}},{"text":"%pyspark\ntrng_avg_rating = nnTrngDF.agg(Fun.avg(Fun.col(\"rating\"))).alias(\"avg\").collect()\nnAvgTestDF = nTestDF.withColumn(\"prediction\",Fun.lit(trng_avg_rating[0][0]))\nnTestDF.unpersist()\nprint(\"Checking the RMSE for the average rating: {0:3.4f}\".format(evaluator.evaluate(nAvgTestDF.filter(nAvgTestDF.prediction != float('nan')))))","user":"anonymous","dateUpdated":"2017-07-30T03:49:03+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501385831573_2119695751","id":"20170730-033711_501217705","dateCreated":"2017-07-30T03:37:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1250","dateFinished":"2017-07-30T03:49:04+0000","dateStarted":"2017-07-30T03:49:03+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Checking the RMSE for the average rating: 1.0516\n"}]}},{"text":"%md\n## Displaying the top 20 recommendations for us.","user":"anonymous","dateUpdated":"2017-07-30T04:27:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501388819842_-171592340","id":"20170730-042659_1480279151","dateCreated":"2017-07-30T04:26:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2964","dateFinished":"2017-07-30T04:27:29+0000","dateStarted":"2017-07-30T04:27:29+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Displaying the top 20 recommendations for us.</h2>\n"}]}},{"text":"%pyspark\nprint(\"************************************\")\nprint(\"*Top 20 recommended movies for you:*\")\nprint(\"************************************\")\nallMoviesDF = spark.read.option(\"header\",\"true\").csv(ROsrcBkt+\"movies.csv\")\nnallMoviesDF = (allMoviesDF.drop('genres').drop('title'))\nnmyRatingsDF = myRatingsDF.drop('_c0').drop('_c2').drop('_c3').withColumn(\"userId\",Fun.lit(0))\nnnmyRatingsDF = nmyRatingsDF.select(nmyRatingsDF._c1.cast(\"int\"))\nmyRatingsDF.unpersist()\nnnallMoviesDF = nallMoviesDF.select(nallMoviesDF.movieId.cast(\"int\"))\nunratedMoviesDF = nnallMoviesDF.subtract(nnmyRatingsDF)\nnunratedMoviesDF = unratedMoviesDF.withColumn(\"userId\",Fun.lit(0))\nnnunratedMoviesDF = nunratedMoviesDF.select('userId','movieId')\npredictedRatingsDF = model.transform(nnunratedMoviesDF)\nnpredictedRatingsDF = (predictedRatingsDF.filter(predictedRatingsDF['prediction'] != float('nan'))).orderBy(\"prediction\",ascending=False)\nfor data in npredictedRatingsDF.take(20):\n    print(\"{}\".format((allMoviesDF.select(\"title\").filter(data.movieId == allMoviesDF.movieId).collect())[0]['title'].encode(\"utf-8\")))","user":"anonymous","dateUpdated":"2017-07-30T03:49:08+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501385893914_1121180410","id":"20170730-033813_1754011937","dateCreated":"2017-07-30T03:38:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1339","dateFinished":"2017-07-30T03:49:24+0000","dateStarted":"2017-07-30T03:49:08+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"************************************\n*Top 20 recommended movies for you:*\n************************************\nDead Man (1995)\nIt Follows (2014)\nThe Artist (2011)\nMan Bites Dog (C'est arrivé près de chez vous) (1992)\nBad and the Beautiful, The (1952)\nTell No One (Ne le dis à personne) (2006)\nBatman (1966)\nMortal Thoughts (1991)\nHow to Marry a Millionaire (1953)\nFaster Pussycat! Kill! Kill! (1965)\nAppleseed (Appurushîdo) (2004)\nMan Without a Past, The (Mies vailla menneisyyttä) (2002)\nProphecy, The (1995)\nHands on a Hard Body (1996)\nPillow Book, The (1996)\nDefiance (2008)\nMindhunters (2004)\nBattle Creek Brawl (Big Brawl, The) (1980)\nAmerican Ninja 3: Blood Hunt (1989)\nArmour of God (Long xiong hu di) (1987)\n"}]}},{"text":"%sql\n","user":"anonymous","dateUpdated":"2017-07-30T06:05:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql","editorHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501394209637_-954602692","id":"20170730-055649_1524668679","dateCreated":"2017-07-30T05:56:49+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5671"}],"name":"WorkshopNoteBook","id":"2CPP5KQNX","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}